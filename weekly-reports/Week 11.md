# Week  11

![IMG_2984.JPG](Week%2011%20f784d63804314ea6affac8edffa0ec27/IMG_2984.jpg)

Guest speaker:

Mohit Bhoite

Mohit Bhoite works as a senior hardware engineer at [Particle](https://www.particle.io/), where he designs and builds their flagship IoT products. He is also an avid maker who dedicates his personal time to building free-formed electronic circuit sculptures. He combines his background in electronics and robotics to create static and kinetic sculptures that convey information fetched over the internet through sound, light, and motion. These sculptures sometimes take on an anthropomorphic form thereby leading the viewer to attach personalities and emotions to them.

Mohit holds a master’s degree in Robotics from the University of Pennsylvania. He spent his time there as a research assistant at the [ModLab](https://www.modlabupenn.org/) helping build the next generation of modular robotics. Prior to this, he worked at a startup in Mumbai, India, developing robotic kits and conducting STEM-focused workshops for high school and university students all across the country.

****Everything announced at OpenAI’s first developer event****

![Untitled](Week%2011%20f784d63804314ea6affac8edffa0ec27/Untitled.png)

1. GPT-4 Turbo with 128K context and lower prices: This is an advanced language model that offers a massive 128,000-word context window, allowing it to generate text with even more context and coherence. Additionally, it comes with lower pricing, making it more accessible to developers.
2. The new Assistants API: This API provides developers with the ability to integrate intelligent virtual assistants into their applications, leveraging the power of GPT-4 Turbo to create conversational and helpful AI-driven virtual assistants.
3. GPT-4 Turbo with Vision: This version of GPT-4 is enhanced with the capability to understand and generate text based on visual inputs. It can process images and provide textual descriptions, making it valuable for applications that involve image analysis and natural language generation.
4. DALL·E 3 API: DALL·E is known for its ability to generate images from text descriptions. The DALL·E 3 API allows developers to harness this image generation technology in their own applications, creating a bridge between text and visual content.

**The Human Impact of this Iteration**

1. Improved Natural Language Understanding: GPT-4 Turbo with 128K context and the new Assistants API can enhance human-computer interactions by providing more context-aware and coherent responses in natural language. This can lead to more efficient and intuitive user experiences in chatbots, virtual assistants, and customer support applications.
2. Enhanced Visual Understanding: GPT-4 Turbo with Vision introduces the ability for AI to understand and generate text based on visual inputs. This can improve accessibility for individuals with visual impairments and facilitate better content tagging and description in various domains, including social media, e-commerce, and content creation.
3. Creative Content Generation: The DALL·E 3 API extends the capabilities of AI in generating images from text descriptions. This can be used in creative fields, such as graphic design and art, and may empower artists and designers to explore new creative possibilities or automate certain aspects of their work.
4. Lower Costs and Accessibility: The lower pricing for GPT-4 Turbo can make advanced AI models more affordable and accessible to a wider range of developers and organizations. This can democratize AI technology and promote its adoption in various industries, ultimately benefiting a broader spectrum of people.
